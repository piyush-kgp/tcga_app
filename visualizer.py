# -*- coding: utf-8 -*-
"""GradCamTCGA.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1mY6gm8eLleBXe35YcGMW-Hzc4f69dUB_
"""
# !nvidia-smi

# !tar xvzf brca.tar.gz

import torch.nn as nn
import torch.nn.functional as F
from torch.utils.tensorboard import SummaryWriter
from torchvision import datasets, models, transforms
import torch.optim as optim
from torch.utils.data import DataLoader, random_split, Dataset
import torch
import torchvision
from PIL import Image
import argparse
from sklearn.metrics import classification_report
import sklearn.metrics as metrics
from PIL import Image
import numpy as np
import matplotlib.pyplot as plt
import os
import pandas as pd
from PIL import Image, ImageFile
import json
import matplotlib.pyplot as plt
ImageFile.LOAD_TRUNCATED_IMAGES = True


def get_hyperpara(organ):
    organ_parameters = {
        "BRCA": {"optimizer": "RMSprop", "n_units_l0": 87, "lr": 5.943487128044342e-05, "n_layers": 1, "dropout_l0": 0.4494231064473708},
        "COAD": {"n_layers": 2, "n_units_l0": 51, "dropout_l0": 0.3633901781496375, "n_units_l1": 96, "dropout_l1": 0.24938970860378834, "optimizer": "RMSprop", "lr": 9.325098201927569e-05},
        "KICH": {"optimizer": "Adam", "n_layers": 2, "lr": 0.00034174604486655424, "dropout_l1": 0.2590922048730916, "dropout_l0": 0.4508962491601658, "n_units_l0": 85, "n_units_l1": 128},
        "KIRC": {"dropout_l0": 0.23949940999396052, "optimizer": "Adam", "lr": 7.340640278726522e-05, "dropout_l1": 0.23075402550504015, "n_layers": 2, "n_units_l0": 90, "n_units_l1": 60},
        "KIRP": {"optimizer": "Adam", "n_units_l0": 101, "lr": 0.0001821856779144607, "n_units_l1": 127, "dropout_l0": 0.20045233657011846, "n_layers": 2, "dropout_l1": 0.24987265944230833},
        "LIHC": {"lr": 0.000305882784838735, "n_units_l1": 46, "n_layers": 2, "dropout_l1": 0.33086051605996936, "dropout_l0": 0.3992380294683205, "n_units_l0": 30, "optimizer": "Adam"},
        "LUAD": {"dropout_l1": 0.40199979514662076, "lr": 0.022804111060047597, "n_layers": 2, "dropout_l0": 0.2494019459238684, "n_units_l0": 56, "optimizer": "SGD", "n_units_l1": 72},
        "LUSC": {"dropout_l0": 0.36601040402058993, "lr": 0.00012063189382769252, "dropout_l2": 0.23198155500094464, "dropout_l1": 0.46238255107808696, "n_units_l1": 5, "n_units_l0": 128, "optimizer": "Adam", "n_units_l2": 79, "n_layers": 3},
        "PRAD": {"lr": 0.00041534966057817655, "n_layers": 1, "dropout_l0": 0.36193748808143655, "optimizer": "Adam", "n_units_l0": 85},
        "READ": {"n_units_l1": 4, "n_layers": 3, "n_units_l2": 101, "optimizer": "Adam", "lr": 0.00010345081363438437, "dropout_l1": 0.32566024092209167, "n_units_l0": 114, "dropout_l0": 0.3736031169357898, "dropout_l2": 0.4320328109269479},
        "STAD": {"n_layers": 1, "lr": 1.931750132804336e-05, "dropout_l0": 0.4365385207030711, "n_units_l0": 92, "optimizer": "Adam"}
    }
    dropouts = []
    hidden_layer_units = []
    for i in range(organ_parameters[organ]['n_layers']):
        dropouts.append(organ_parameters[organ]['dropout_l{}'.format(i)])
        hidden_layer_units.append(organ_parameters[organ]['n_units_l{}'.format(i)])
    optimizer = organ_parameters[organ]['optimizer']
    lr = organ_parameters[organ]['lr']
    return dropouts,hidden_layer_units,optimizer,lr

def define_model(dropouts,hidden_layer_units,num_classes=2):
    # We optimize the number of layers, hidden untis and dropout ratio in each layer.
    layers = []
    model = models.resnet18(pretrained=True)
    in_features = model.fc.in_features
    for i in range(len(dropouts)):
        out_features = hidden_layer_units[i]
        layers.append(nn.Linear(in_features, out_features))
        layers.append(nn.ReLU())
        p = dropouts[i]
        layers.append(nn.Dropout(p))
        in_features = out_features
    layers.append(nn.Linear(in_features, num_classes))
    model.fc = nn.Sequential(*layers)
    return model


def get_output(fp, outfile, organ):

    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print("DEVICE {}".format(device), flush=True)

    model_checkpoint = "CheckPoints/{}_best_model.pth".format(organ)
    ckpt = torch.load(model_checkpoint) if device=="cuda" else \
           torch.load(model_checkpoint, map_location=torch.device('cpu'))
    ckpt = {k.replace("module.", ""): v for k, v in ckpt.items()}

    dropouts,hidden_layer_units,optimizer_name,lr = get_hyperpara(organ)
    model = define_model(dropouts,hidden_layer_units,num_classes=2)
    model.load_state_dict(ckpt)

    model = model.to(device)

    data_transform = transforms.Compose([
        transforms.Resize(256),
        transforms.CenterCrop(224),
        transforms.ToTensor(),
        transforms.Normalize([0.596, 0.436, 0.586], [0.2066, 0.240, 0.186])
        ])

    img = Image.open(fp)
    X = data_transform(img)
    X = X.reshape(-1,3,224,224)
    Y = "cancer"

    model.eval()
    modules = list(model.children())[:8]
    model_gc = nn.Sequential(*modules)
    for p in model_gc.parameters():
        p.requires_grad = False
    activation = model_gc(X.to(device)).reshape((512,49))

    sd = model.state_dict()
    w1 = sd["fc.0.weight"]
    w2 = sd["fc.3.weight"]

    idx = 0 if Y=="Cancer" else 1
    weight = (w1.T@w2.T)[:,idx].reshape(512)

    cam = (weight@activation).reshape(7,7)
    upsampler = nn.Upsample(scale_factor=32, mode='bicubic')
    output = upsampler(cam.reshape(1,1,7,7)).reshape(224,224)

    output = (output-output.min())/(output.max()-output.min())
    output = output.cpu().numpy()
    output = (255*output).astype(np.uint8)
    Image.fromarray(output).save("out.jpg")

    def apply_colormap_on_image(org_im, activation, colormap_name):
        import matplotlib.cm as mpl_color_map, copy
        """
            Apply heatmap on image
        Args:
            org_img (PIL img): Original image
            activation_map (numpy arr): Activation map (grayscale) 0-255
            colormap_name (str): Name of the colormap
        """
        # Get colormap
        color_map = mpl_color_map.get_cmap(colormap_name)
        no_trans_heatmap = color_map(activation)
        # Change alpha channel in colormap to make sure original image is displayed
        heatmap = copy.copy(no_trans_heatmap)
        heatmap[:, :, 3] = 0.4
        heatmap = Image.fromarray((heatmap*255).astype(np.uint8))
        no_trans_heatmap = Image.fromarray((no_trans_heatmap*255).astype(np.uint8))

        # Apply heatmap on iamge
        heatmap_on_image = Image.new("RGBA", org_im.size)
        heatmap_on_image = Image.alpha_composite(heatmap_on_image, org_im.convert('RGBA'))
        heatmap_on_image = Image.alpha_composite(heatmap_on_image, heatmap)
        return no_trans_heatmap, heatmap_on_image

    cm = plt.get_cmap('jet')
    colored_image = Image.fromarray((cm(output)*255).astype(np.uint8))
    colored_image.save(outfile)
    pred = model(X.to(device)).reshape(2,).argmax().item()
    print(organ, pred, outfile)
    return pred
